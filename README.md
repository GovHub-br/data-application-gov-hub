# Gov Hub BR - Transformando Dados em Valor para GestÃ£o PÃºblica

O Gov Hub BR Ã© uma iniciativa para enfrentar os desafios da fragmentaÃ§Ã£o, redundÃ¢ncia e inconsistÃªncias nos sistemas estruturantes do governo federal. O projeto busca transformar dados pÃºblicos em ativos estratÃ©gicos, promovendo eficiÃªncia administrativa, transparÃªncia e melhor tomada de decisÃ£o. A partir da integraÃ§Ã£o de dados, gestores pÃºblicos terÃ£o acesso a informaÃ§Ãµes qualificadas para subsidiar decisÃµes mais assertivas, reduzir custos operacionais e otimizar processos internos. 

Potencializamos informaÃ§Ãµes de sistemas como TransfereGov, Siape, Siafi, ComprasGov e Siorg para gerar diagnÃ³sticos estratÃ©gicos, indicadores confiÃ¡veis e decisÃµes baseadas em evidÃªncias.

![InformaÃ§Ãµes do Projeto](docs/land/dist/images/imagem_informacoes.jpg)

- TransparÃªncia pÃºblica e cultura de dados abertos
- Indicadores confiÃ¡veis para acompanhamento e monitoramento
- DecisÃµes baseadas em evidÃªncias e diagnÃ³sticos estratÃ©gicos
- ExploraÃ§Ã£o de inteligÃªncia artificial para gerar insights
- GestÃ£o orientada a dados em todos os nÃ­veis

## Fluxo/Arquitetura de Dados

A arquitetura do Gov Hub BR Ã© baseada na Arquitetura Medallion,  em um fluxo de dados que permite a coleta, transformaÃ§Ã£o e visualizaÃ§Ã£o de dados.

![Fluxo de Dados](fluxo_dados.jpg)

Para mais informaÃ§Ãµes sobre o projeto, veja o nosso [e-book](docs/land/dist/ebook/GovHub_Livro-digital_0905.pdf).
E temos tambÃ©m alguns slides falando do projeto e como ele pode ajudar a transformar a gestÃ£o pÃºblica.

[Slides](https://www.figma.com/slides/PlubQE0gaiBBwFAV5GcVlH/Gov-Hub---F%C3%B3rum-IA---Giga-candanga?node-id=5-131&t=hlLiJiwfyPEPRFys-1)

## Apoio

Esse trabalho  Ã© mantido pelo [Lab Livre](https://www.instagram.com/lab.livre/) e apoiado pelo [IPEA/Dides](https://www.ipea.gov.br/portal/categorias/72-estrutura-organizacional/210-dides-estrutura-organizacional).

## Contato

Para dÃºvidas, sugestÃµes ou para contribuir com o projeto, entre em contato conosco: [lablivreunb@gmail.com](mailto:lablivreunb@gmail.com)

# Data Pipeline Project

This project implements a modern data stack using Airflow, dbt, Jupyter, and Superset for data orchestration, transformation, analysis, and visualization.

## ğŸš€ Stack Components

- **Apache Airflow**: Workflow orchestration
- **dbt**: Data transformation
- **Jupyter**: Interactive data analysis
- **Apache Superset**: Data visualization and exploration
- **Docker**: Containerization and local development
- **Make**: Build automation and setup

## ğŸ“‹ Prerequisites

- Docker and Docker Compose
- Make
- Python 3.x
- Git

## ğŸ”§ Setup

1. Clone the repository:
```bash
git clone git@gitlab.com:lappis-unb/gest-odadosipea/app-lappis-ipea.git
cd app-lappis-ipea
```

2. Run the setup using Make:
```bash
make setup
```

This will:
- Create necessary virtual environments
- Install dependencies
- Set up pre-commit hooks
- Configure development environment

## ğŸƒâ€â™‚ï¸ Running Locally

Start all services using Docker Compose:

```bash
docker-compose up -d
```

Access the different components:
- Airflow: http://localhost:8080
- Jupyter: http://localhost:8888
- Superset: http://localhost:8088

## ğŸ’» Development

### Code Quality

This project uses several tools to maintain code quality:
- Pre-commit hooks
- Linting configurations
- Automated testing

Run linting checks:
```bash
make lint
```

Run tests:
```bash
make test
```

### Project Structure

```
.
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/
â”‚   â””â”€â”€ plugins/
â”œâ”€â”€ dbt/
â”‚   â””â”€â”€ models/
â”œâ”€â”€ jupyter/
â”‚   â””â”€â”€ notebooks/
â”œâ”€â”€ superset/
â”‚   â””â”€â”€ dashboards/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Makefile
â””â”€â”€ README.md
```

### Makefile Commands

- `make setup`: Initial project setup
- `make lint`: Run linting checks
- `make tests`: Run test suite
- `make clean`: Clean up generated files
- `make build`: Build Docker images

## ğŸ” Git Workflow

This project requires signed commits. To set up GPG signing:

1. Generate a GPG key:
```bash
gpg --full-generate-key
```

2. Configure Git to use GPG signing:
```bash
git config --global user.signingkey YOUR_KEY_ID
git config --global commit.gpgsign true
```

3. Add your GPG key to your GitLab account

## ğŸ“š Documentation

- [Airflow Documentation](https://airflow.apache.org/docs/)
- [dbt Documentation](https://docs.getdbt.com/)
- [Superset Documentation](https://superset.apache.org/docs/intro)

## ğŸ¤ Contributing

1. Create a new branch for your feature
2. Make changes and ensure all tests pass
3. Submit a merge request
